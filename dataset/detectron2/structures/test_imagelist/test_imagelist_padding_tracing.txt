@staticmethod
def from_tensors(tensors: List[torch.Tensor], size_divisibility: int=0, pad_value: float=0.0, padding_constraints: Optional[Dict[str, int]]=None) -> 'ImageList':
    """
        Args:
            tensors: a tuple or list of `torch.Tensor`, each of shape (Hi, Wi) or
                (C_1, ..., C_K, Hi, Wi) where K >= 1. The Tensors will be padded
                to the same shape with `pad_value`.
            size_divisibility (int): If `size_divisibility > 0`, add padding to ensure
                the common height and width is divisible by `size_divisibility`.
                This depends on the model and many models need a divisibility of 32.
            pad_value (float): value to pad.
            padding_constraints (optional[Dict]): If given, it would follow the format as
                {"size_divisibility": int, "square_size": int}, where `size_divisibility` will
                overwrite the above one if presented and `square_size` indicates the
                square padding size if `square_size` > 0.
        Returns:
            an `ImageList`.
        """
    assert len(tensors) > 0
    assert isinstance(tensors, (tuple, list))
    for t in tensors:
        assert isinstance(t, torch.Tensor), type(t)
        assert t.shape[:-2] == tensors[0].shape[:-2], t.shape
    image_sizes = [(im.shape[-2], im.shape[-1]) for im in tensors]
    image_sizes_tensor = [shapes_to_tensor(x) for x in image_sizes]
    max_size = torch.stack(image_sizes_tensor).max(0).values
    if padding_constraints is not None:
        square_size = padding_constraints.get('square_size', 0)
        if square_size > 0:
            max_size[0] = max_size[1] = square_size
        if 'size_divisibility' in padding_constraints:
            size_divisibility = padding_constraints['size_divisibility']
    if size_divisibility > 1:
        stride = size_divisibility
        max_size = (max_size + (stride - 1)).div(stride, rounding_mode='floor') * stride
    if torch.jit.is_scripting():
        max_size: List[int] = max_size.to(dtype=torch.long).tolist()
    elif torch.jit.is_tracing():
        image_sizes = image_sizes_tensor
    if len(tensors) == 1:
        image_size = image_sizes[0]
        padding_size = [0, max_size[-1] - image_size[1], 0, max_size[-2] - image_size[0]]
        batched_imgs = F.pad(tensors[0], padding_size, value=pad_value).unsqueeze_(0)
    else:
        batch_shape = [len(tensors)] + list(tensors[0].shape[:-2]) + list(max_size)
        device = None if torch.jit.is_scripting() else 'cpu' if torch.jit.is_tracing() else None
        batched_imgs = tensors[0].new_full(batch_shape, pad_value, device=device)
        batched_imgs = move_device_like(batched_imgs, tensors[0])
        for (i, img) in enumerate(tensors):
            batched_imgs[i, ..., :img.shape[-2], :img.shape[-1]].copy_(img)
    return ImageList(batched_imgs.contiguous(), image_sizes)

----------

def test_imagelist_padding_tracing(self):

    def to_imagelist(tensors: Sequence[torch.Tensor]):
        image_list = ImageList.from_tensors(tensors, 4)
        return (image_list.tensor, image_list.image_sizes)

    def _tensor(*shape):
        return torch.ones(shape, dtype=torch.float32)
    for shape in [(3, 10, 10), (3, 12, 12)]:
        func = torch.jit.trace(to_imagelist, ([_tensor(*shape)],))
        (tensor, image_sizes) = func([_tensor(3, 15, 20)])
        self.assertEqual(tensor.shape, (1, 3, 16, 20), tensor.shape)
        self.assertEqual(image_sizes[0].tolist(), [15, 20], image_sizes[0])
    func = torch.jit.trace(to_imagelist, ([_tensor(10, 10)],))
    (tensor, image_sizes) = func([_tensor(15, 20)])
    self.assertEqual(tensor.shape, (1, 16, 20), tensor.shape)
    self.assertEqual(image_sizes[0].tolist(), [15, 20], image_sizes[0])
    func = torch.jit.trace(to_imagelist, ([_tensor(3, 16, 10), _tensor(3, 13, 11)],))
    (tensor, image_sizes) = func([_tensor(3, 25, 20), _tensor(3, 10, 10)])
    self.assertEqual(tensor.shape, (2, 3, 28, 20), tensor.shape)
    self.assertEqual(image_sizes[0].tolist(), [25, 20], image_sizes[0])
    self.assertEqual(image_sizes[1].tolist(), [10, 10], image_sizes[1])

----------



Test Class Name: TestImageList