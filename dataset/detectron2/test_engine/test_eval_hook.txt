def train(self):
    """
        Run training.

        Returns:
            OrderedDict of results, if evaluation is enabled. Otherwise None.
        """
    super().train(self.start_iter, self.max_iter)
    if len(self.cfg.TEST.EXPECTED_RESULTS) and comm.is_main_process():
        assert hasattr(self, '_last_eval_results'), 'No evaluation results obtained during training!'
        verify_results(self.cfg, self._last_eval_results)
        return self._last_eval_results

----------

def test_eval_hook(self):
    model = _SimpleModel()
    dataloader = self._data_loader('cpu')
    opt = torch.optim.SGD(model.parameters(), 0.1)
    for (total_iter, period, eval_count) in [(30, 15, 2), (31, 15, 3), (20, 0, 1)]:
        test_func = mock.Mock(return_value={'metric': 3.0})
        trainer = SimpleTrainer(model, dataloader, opt)
        trainer.register_hooks([hooks.EvalHook(period, test_func)])
        trainer.train(0, total_iter)
        self.assertEqual(test_func.call_count, eval_count)

----------

def _data_loader(self, device):
    device = torch.device(device)
    while True:
        yield torch.rand(3, 3).to(device)

Test Class Name: TestTrainer