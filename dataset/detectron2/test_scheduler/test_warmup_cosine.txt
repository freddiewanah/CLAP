@staticmethod
def backward(ctx, grad):
    shape = ctx.shape
    return (_NewEmptyTensorOp.apply(grad, shape), None)

----------

def test_warmup_cosine(self):
    p = nn.Parameter(torch.zeros(0))
    opt = torch.optim.SGD([p], lr=5)
    multiplier = WarmupParamScheduler(CosineParamScheduler(1, 0), 0.001, 5 / 30)
    sched = LRMultiplier(opt, multiplier, 30)
    p.sum().backward()
    opt.step()
    self.assertEqual(opt.param_groups[0]['lr'], 0.005)
    lrs = [0.005]
    for _ in range(30):
        sched.step()
        lrs.append(opt.param_groups[0]['lr'])
    for (idx, lr) in enumerate(lrs):
        expected_cosine = 2.5 * (1.0 + math.cos(math.pi * idx / 30))
        if idx >= 5:
            self.assertAlmostEqual(lr, expected_cosine)
        else:
            self.assertNotAlmostEqual(lr, expected_cosine)

----------



Test Class Name: TestScheduler