@staticmethod
def backward(ctx, grad):
    shape = ctx.shape
    return (_NewEmptyTensorOp.apply(grad, shape), None)

----------

def test_warmup_stepwithfixedgamma(self):
    p = nn.Parameter(torch.zeros(0))
    opt = torch.optim.SGD([p], lr=5)
    multiplier = WarmupParamScheduler(StepWithFixedGammaParamScheduler(base_value=1.0, gamma=0.1, num_decays=4, num_updates=30), 0.001, 5 / 30, rescale_interval=True)
    sched = LRMultiplier(opt, multiplier, 30)
    p.sum().backward()
    opt.step()
    lrs = [0.005]
    for _ in range(29):
        sched.step()
        lrs.append(opt.param_groups[0]['lr'])
    self.assertTrue(np.allclose(lrs[:5], [0.005, 1.004, 2.003, 3.002, 4.001]))
    self.assertTrue(np.allclose(lrs[5:10], 5.0))
    self.assertTrue(np.allclose(lrs[10:15], 0.5))
    self.assertTrue(np.allclose(lrs[15:20], 0.05))
    self.assertTrue(np.allclose(lrs[20:25], 0.005))
    self.assertTrue(np.allclose(lrs[25:], 0.0005))
    with self.assertRaises(IndexError, msg='list index out of range'):
        sched.step()

----------



Test Class Name: TestScheduler