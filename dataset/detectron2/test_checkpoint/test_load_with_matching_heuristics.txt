def load(self, path, *args, **kwargs):
    assert self._parsed_url_during_load is None
    need_sync = False
    logger = logging.getLogger(__name__)
    logger.info('[DetectionCheckpointer] Loading from {} ...'.format(path))
    if path and isinstance(self.model, DistributedDataParallel):
        path = self.path_manager.get_local_path(path)
        has_file = os.path.isfile(path)
        all_has_file = comm.all_gather(has_file)
        if not all_has_file[0]:
            raise OSError(f'File {path} not found on main worker.')
        if not all(all_has_file):
            logger.warning(f'Not all workers can read checkpoint {path}. Training may fail to fully resume.')
            need_sync = True
        if not has_file:
            path = None
    if path:
        parsed_url = urlparse(path)
        self._parsed_url_during_load = parsed_url
        path = parsed_url._replace(query='').geturl()
        path = self.path_manager.get_local_path(path)
    ret = super().load(path, *args, **kwargs)
    if need_sync:
        logger.info('Broadcasting model states from main worker ...')
        self.model._sync_params_and_buffers()
    self._parsed_url_during_load = None
    return ret

----------

def test_load_with_matching_heuristics(self):
    with tempfile.TemporaryDirectory(prefix='detectron2_test') as d:
        (model, state_dict) = self.create_complex_model()
        torch.save({'model': state_dict}, os.path.join(d, 'checkpoint.pth'))
        checkpointer = DetectionCheckpointer(model, save_dir=d)
        with torch.no_grad():
            model.block1.layer1.weight.fill_(1)
        checkpointer.load(os.path.join(d, 'checkpoint.pth'))
        self.assertTrue(model.block1.layer1.weight.equal(torch.ones(3, 2)))
        checkpointer.load(os.path.join(d, 'checkpoint.pth?matching_heuristics=True'))
        self.assertFalse(model.block1.layer1.weight.equal(torch.ones(3, 2)))

----------



Test Class Name: TestCheckpointer