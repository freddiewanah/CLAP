def gen_crop_transform_with_instance(crop_size, image_size, instance):
    """
    Generate a CropTransform so that the cropping region contains
    the center of the given instance.

    Args:
        crop_size (tuple): h, w in pixels
        image_size (tuple): h, w
        instance (dict): an annotation dict of one instance, in Detectron2's
            dataset format.
    """
    crop_size = np.asarray(crop_size, dtype=np.int32)
    bbox = BoxMode.convert(instance['bbox'], instance['bbox_mode'], BoxMode.XYXY_ABS)
    center_yx = ((bbox[1] + bbox[3]) * 0.5, (bbox[0] + bbox[2]) * 0.5)
    assert image_size[0] >= center_yx[0] and image_size[1] >= center_yx[1], 'The annotation bounding box is outside of the image!'
    assert image_size[0] >= crop_size[0] and image_size[1] >= crop_size[1], 'Crop size is larger than image size!'
    min_yx = np.maximum(np.floor(center_yx).astype(np.int32) - crop_size, 0)
    max_yx = np.maximum(np.asarray(image_size, dtype=np.int32) - crop_size, 0)
    max_yx = np.minimum(max_yx, np.ceil(center_yx).astype(np.int32))
    y0 = np.random.randint(min_yx[0], max_yx[0] + 1)
    x0 = np.random.randint(min_yx[1], max_yx[1] + 1)
    return T.CropTransform(x0, y0, crop_size[1], crop_size[0])

----------

def test_gen_crop(self):
    instance = {'bbox': [10, 10, 100, 100], 'bbox_mode': BoxMode.XYXY_ABS}
    t = detection_utils.gen_crop_transform_with_instance((10, 10), (150, 150), instance)
    self.assertTrue(t.x0 <= 55 <= t.x0 + t.w)

----------



Test Class Name: TestTransformAnnotations