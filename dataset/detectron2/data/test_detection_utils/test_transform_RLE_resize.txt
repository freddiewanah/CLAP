def annotations_to_instances(annos, image_size, mask_format='polygon'):
    """
    Create an :class:`Instances` object used by the models,
    from instance annotations in the dataset dict.

    Args:
        annos (list[dict]): a list of instance annotations in one image, each
            element for one instance.
        image_size (tuple): height, width

    Returns:
        Instances:
            It will contain fields "gt_boxes", "gt_classes",
            "gt_masks", "gt_keypoints", if they can be obtained from `annos`.
            This is the format that builtin models expect.
    """
    boxes = np.stack([BoxMode.convert(obj['bbox'], obj['bbox_mode'], BoxMode.XYXY_ABS) for obj in annos]) if len(annos) else np.zeros((0, 4))
    target = Instances(image_size)
    target.gt_boxes = Boxes(boxes)
    classes = [int(obj['category_id']) for obj in annos]
    classes = torch.tensor(classes, dtype=torch.int64)
    target.gt_classes = classes
    if len(annos) and 'segmentation' in annos[0]:
        segms = [obj['segmentation'] for obj in annos]
        if mask_format == 'polygon':
            try:
                masks = PolygonMasks(segms)
            except ValueError as e:
                raise ValueError("Failed to use mask_format=='polygon' from the given annotations!") from e
        else:
            assert mask_format == 'bitmask', mask_format
            masks = []
            for segm in segms:
                if isinstance(segm, list):
                    masks.append(polygons_to_bitmask(segm, *image_size))
                elif isinstance(segm, dict):
                    masks.append(mask_util.decode(segm))
                elif isinstance(segm, np.ndarray):
                    assert segm.ndim == 2, 'Expect segmentation of 2 dimensions, got {}.'.format(segm.ndim)
                    masks.append(segm)
                else:
                    raise ValueError("Cannot convert segmentation of type '{}' to BitMasks!Supported types are: polygons as list[list[float] or ndarray], COCO-style RLE as a dict, or a binary segmentation mask  in a 2D numpy array of shape HxW.".format(type(segm)))
            masks = BitMasks(torch.stack([torch.from_numpy(np.ascontiguousarray(x)) for x in masks]))
        target.gt_masks = masks
    if len(annos) and 'keypoints' in annos[0]:
        kpts = [obj.get('keypoints', []) for obj in annos]
        target.gt_keypoints = Keypoints(kpts)
    return target

----------

def test_transform_RLE_resize(self):
    transforms = T.TransformList([T.HFlipTransform(400), T.ScaleTransform(300, 400, 400, 400, 'bilinear')])
    mask = np.zeros((300, 400), order='F').astype('uint8')
    mask[:, :200] = 1
    anno = {'bbox': np.asarray([10, 10, 200, 300]), 'bbox_mode': BoxMode.XYXY_ABS, 'segmentation': mask_util.encode(mask[:, :, None])[0], 'category_id': 3}
    output = detection_utils.transform_instance_annotations(copy.deepcopy(anno), transforms, (400, 400))
    inst = detection_utils.annotations_to_instances([output, output], (400, 400), mask_format='bitmask')
    self.assertTrue(isinstance(inst.gt_masks, BitMasks))

----------



Test Class Name: TestTransformAnnotations