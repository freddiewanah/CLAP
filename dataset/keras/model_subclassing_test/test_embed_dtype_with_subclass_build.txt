def build(self, input_shape):
    self.layer2 = keras.layers.Dense(1, activation='relu')

----------

def test_embed_dtype_with_subclass_build(self):

    class Embedding(keras.layers.Layer):
        """An Embedding layer."""

        def __init__(self, vocab_size, embedding_dim, **kwargs):
            super().__init__(**kwargs)
            self.vocab_size = vocab_size
            self.embedding_dim = embedding_dim

        def build(self, _):
            self.embedding = self.add_weight('embedding_kernel', shape=[self.vocab_size, self.embedding_dim], dtype=np.float32, initializer=tf.compat.v1.random_uniform_initializer(-0.1, 0.1), trainable=True)

        def call(self, x):
            return tf.compat.v1.nn.embedding_lookup(self.embedding, x)

    class EmbedModel(keras.Model):

        def __init__(self, vocab_size, embed_size):
            super().__init__()
            self.embed1 = Embedding(vocab_size, embed_size)

        def call(self, inputs):
            return self.embed1(inputs)
    model = EmbedModel(100, 20)
    self.assertFalse(model.built, 'Model should not have been built')
    self.assertFalse(model.weights, 'Model should have no weights since it has not been built.')
    with self.assertRaisesRegex(ValueError, 'if your layers do not support float type inputs'):
        model.build(input_shape=(35, 20))

----------



Test Class Name: default