def test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True):
    """Test the model on a single batch of samples.

        Args:
            x: Input data. It could be:
              - A Numpy array (or array-like), or a list of arrays
                (in case the model has multiple inputs).
              - A TensorFlow tensor, or a list of tensors
                (in case the model has multiple inputs).
              - A dict mapping input names to the corresponding array/tensors,
                if the model has named inputs.
              - A `tf.data` dataset.
            y: Target data. Like the input data `x`,
              it could be either Numpy array(s) or TensorFlow tensor(s).
              It should be consistent with `x` (you cannot have Numpy inputs and
              tensor targets, or inversely). If `x` is a dataset `y` should
              not be specified (since targets will be obtained from the
              iterator).
            sample_weight: Optional array of the same length as x, containing
                weights to apply to the model's loss for each sample.
                In the case of temporal data, you can pass a 2D array
                with shape (samples, sequence_length),
                to apply a different weight to every timestep of every sample.
                In this case you should make sure to specify
                sample_weight_mode="temporal" in compile(). This argument is not
                supported when `x` is a dataset.
            reset_metrics: If `True`, the metrics returned will be only for this
              batch. If `False`, the metrics will be statefully accumulated
              across batches.

        Returns:
            Scalar test loss (if the model has a single output and no metrics)
            or list of scalars (if the model has multiple outputs
            and/or metrics). The attribute `model.metrics_names` will give you
            the display labels for the scalar outputs.

        Raises:
            ValueError: In case of invalid user-provided arguments.
        """
    self._assert_compile_was_called()
    self._check_call_args('test_on_batch')
    if self._distribution_strategy and tf.distribute.in_cross_replica_context():
        raise NotImplementedError('`test_on_batch` is not supported for models distributed with tf.distribute.Strategy.')
    (x, y, sample_weights) = self._standardize_user_data(x, y, sample_weight=sample_weight, extract_tensors_from_dataset=True)
    if self.run_eagerly or self._distribution_strategy:
        output_dict = training_eager_v1.test_on_batch(self, x, y, sample_weights=sample_weights, output_loss_metrics=self._output_loss_metrics)
        outputs = output_dict['total_loss'] + output_dict['output_losses'] + output_dict['metrics']
        outputs = [_non_none_constant_value(v) for v in outputs]
    else:
        x = training_utils_v1.ModelInputs(x).as_list()
        inputs = x + list(y or []) + list(sample_weights or [])
        self._update_sample_weight_modes(sample_weights=sample_weights)
        self._make_test_function()
        outputs = self.test_function(inputs)
    if reset_metrics:
        self.reset_metrics()
    if len(outputs) == 1:
        return outputs[0]
    return outputs

----------

@test_combinations.run_all_keras_modes
def test_loss_with_sample_weight_in_layer_call(self):

    class MyLayer(layers.Layer):

        def __init__(self):
            super().__init__()
            self.bias = test_utils.Bias()

        def call(self, inputs):
            out = self.bias(inputs[0])
            self.add_loss(MAE()(inputs[1], out, inputs[2]))
            self.add_loss(tf.reduce_mean(inputs[2] * mae(inputs[1], out)))
            return out
    inputs = Input(shape=(1,))
    targets = Input(shape=(1,))
    sw = Input(shape=(1,))
    outputs = MyLayer()([inputs, targets, sw])
    model = Model([inputs, targets, sw], outputs)
    model.predict([self.x, self.y, self.w])
    model.compile(optimizer_legacy.gradient_descent.SGD(0.05), run_eagerly=test_utils.should_run_eagerly())
    history = model.fit([self.x, self.y, self.w], batch_size=3, epochs=5)
    self.assertAllClose(history.history['loss'], [2.0, 1.8, 1.6, 1.4, 1.2], 0.001)
    output = model.evaluate([self.x, self.y, self.w])
    self.assertAlmostEqual(output, 1.0, 3)
    output = model.test_on_batch([self.x, self.y, self.w])
    self.assertAlmostEqual(output, 1.0, 3)

----------



Test Class Name: default