@traceback_utils.filter_traceback
def save(self, filepath, overwrite=True, save_format=None, **kwargs):
    """Saves a model as a TensorFlow SavedModel or HDF5 file.

        See the [Serialization and Saving guide](
            https://keras.io/guides/serialization_and_saving/) for details.

        Args:
            model: Keras model instance to be saved.
            filepath: `str` or `pathlib.Path` object. Path where to save the
                model.
            overwrite: Whether we should overwrite any existing model at the
                target location, or instead ask the user via an interactive
                prompt.
            save_format: Either `"keras"`, `"tf"`, `"h5"`,
                indicating whether to save the model
                in the native Keras format (`.keras`),
                in the TensorFlow SavedModel format
                (referred to as "SavedModel" below),
                or in the legacy HDF5 format (`.h5`).
                Defaults to `"tf"` in TF 2.X, and `"h5"` in TF 1.X.

        SavedModel format arguments:
            include_optimizer: Only applied to SavedModel and legacy HDF5
                formats. If False, do not save the optimizer state.
                Defaults to True.
            signatures: Only applies to SavedModel format. Signatures to save
                with the SavedModel. See the `signatures` argument in
                `tf.saved_model.save` for details.
            options: Only applies to SavedModel format.
                `tf.saved_model.SaveOptions` object that specifies SavedModel
                saving options.
            save_traces: Only applies to SavedModel format. When enabled, the
                SavedModel will store the function traces for each layer. This
                can be disabled, so that only the configs of each layer are
                stored. Defaults to `True`.
                Disabling this will decrease serialization time
                and reduce file size, but it requires that all custom
                layers/models implement a `get_config()` method.

        Example:

        ```python
        model = tf.keras.Sequential([
            tf.keras.layers.Dense(5, input_shape=(3,)),
            tf.keras.layers.Softmax()])
        model.save("model.keras")
        loaded_model = tf.keras.models.load_model("model.keras")
        x = tf.random.uniform((10, 3))
        assert np.allclose(model.predict(x), loaded_model.predict(x))
        ```

        Note that `model.save()` is an alias for `tf.keras.models.save_model()`.
        """
    saving_api.save_model(self, filepath=filepath, overwrite=overwrite, save_format=save_format, **kwargs)

----------

@test_combinations.generate(test_combinations.combine(mode=['eager']))
def testPartialRestoreWarningObject(self):
    optimizer = adam.Adam(0.0)
    original_root = tf.train.Checkpoint(v1=tf.Variable(2.0), v2=tf.Variable(3.0), optimizer=optimizer)
    optimizer.minimize(original_root.v1.read_value, [original_root.v1])
    prefix = os.path.join(self.get_temp_dir(), 'ckpt')
    save_path = original_root.save(prefix)
    partial_root = tf.train.Checkpoint(v1=tf.Variable(0.0))
    weak_partial_root = weakref.ref(partial_root)
    weak_v1 = weakref.ref(partial_root.v1)
    partial_root.restore(save_path)
    self.assertEqual(2.0, partial_root.v1.numpy())
    with tf.compat.v1.test.mock.patch.object(logging, 'warning') as mock_log:
        del partial_root
        self.assertIsNone(weak_partial_root())
        self.assertIsNone(weak_v1())
        messages = str(mock_log.call_args_list)
    self.assertIn("(root).v2'", messages)
    self.assertIn("(root).optimizer's state 'm' for (root).v1", messages)
    self.assertNotIn("(root).v1'", messages)
    self.assertIn('expect_partial()', messages)

----------



Test Class Name: CheckpointingTests