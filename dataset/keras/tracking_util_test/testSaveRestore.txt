@property
def variables(self):
    """Returns variables of this optimizer."""
    return CallableList(self._variables)

----------

@test_combinations.generate(test_combinations.combine(mode=['graph', 'eager']))
def testSaveRestore(self):
    with self.test_session():
        model = MyModel()
        optimizer = adam.Adam(0.001)
        root_trackable = tf.train.Checkpoint(optimizer=optimizer, model=model)
        input_value = tf.constant([[3.0]])
        with tf.GradientTape() as tape:
            loss = model(input_value)
        variables = model.trainable_variables
        gradients = tape.gradient(loss, variables)
        train_op = optimizer.apply_gradients(zip(gradients, variables))
        self.assertFalse(root_trackable.save_counter.trainable)
        self.evaluate(trackable_utils.gather_initializers(root_trackable))
        self.evaluate(train_op)
        prefix = os.path.join(self.get_temp_dir(), 'ckpt')
        self.evaluate(tf.compat.v1.assign(model._named_dense.variables[1], [42.0]))
        m_bias_slot = optimizer.get_slot(model._named_dense.variables[1], 'm')
        self.evaluate(tf.compat.v1.assign(m_bias_slot, [1.5]))
        save_path = root_trackable.save(file_prefix=prefix)
        self.evaluate(tf.compat.v1.assign(model._named_dense.variables[1], [43.0]))
        self.evaluate(tf.compat.v1.assign(root_trackable.save_counter, 3))
        optimizer_variables = self.evaluate(sorted(optimizer.variables(), key=lambda v: v.name))
        self.evaluate(tf.compat.v1.assign(m_bias_slot, [-2.0]))
        status = root_trackable.restore(save_path=save_path).assert_consumed()
        status.run_restore_ops()
        self.assertAllEqual([42.0], self.evaluate(model._named_dense.variables[1]))
        self.assertAllEqual(1, self.evaluate(root_trackable.save_counter))
        self.assertAllEqual([1.5], self.evaluate(m_bias_slot))
        if not tf.executing_eagerly():
            return
        on_create_model = MyModel()
        on_create_optimizer = adam.Adam(0.001)
        on_create_root = tf.train.Checkpoint(optimizer=on_create_optimizer, model=on_create_model)
        status = on_create_root.restore(save_path=save_path)
        status.assert_nontrivial_match()
        status.assert_existing_objects_matched()
        with self.assertRaises(AssertionError):
            status.assert_consumed()
        on_create_model(tf.constant([[3.0]]))
        self.assertAllEqual(1, self.evaluate(on_create_root.save_counter))
        self.assertAllEqual([42.0], self.evaluate(on_create_model._named_dense.variables[1]))
        on_create_m_bias_slot = on_create_optimizer.get_slot(on_create_model._named_dense.variables[1], 'm')
        status.assert_existing_objects_matched()
        if not tf.executing_eagerly():
            with self.assertRaises(AssertionError):
                status.assert_consumed()
        self.assertAllEqual([1.5], self.evaluate(on_create_m_bias_slot))
        dummy_var = tf.Variable([1.0])
        on_create_optimizer.minimize(loss=dummy_var.read_value, var_list=[dummy_var])
        status.assert_existing_objects_matched()
        status.assert_consumed()
        self.assertAllEqual(optimizer_variables, self.evaluate(sorted(optimizer.variables(), key=lambda v: v.name)))

----------



Test Class Name: CheckpointingTests