def fingerprint(request: Request, *, include_headers: Optional[Iterable[Union[bytes, str]]]=None, keep_fragments: bool=False) -> bytes:
    """
    Return the request fingerprint.

    The request fingerprint is a hash that uniquely identifies the resource the
    request points to. For example, take the following two urls:

    http://www.example.com/query?id=111&cat=222
    http://www.example.com/query?cat=222&id=111

    Even though those are two different URLs both point to the same resource
    and are equivalent (i.e. they should return the same response).

    Another example are cookies used to store session ids. Suppose the
    following page is only accessible to authenticated users:

    http://www.example.com/members/offers.html

    Lots of sites use a cookie to store the session id, which adds a random
    component to the HTTP Request and thus should be ignored when calculating
    the fingerprint.

    For this reason, request headers are ignored by default when calculating
    the fingerprint. If you want to include specific headers use the
    include_headers argument, which is a list of Request headers to include.

    Also, servers usually ignore fragments in urls when handling requests,
    so they are also ignored by default when calculating the fingerprint.
    If you want to include them, set the keep_fragments argument to True
    (for instance when handling requests with a headless browser).
    """
    processed_include_headers: Optional[Tuple[bytes, ...]] = None
    if include_headers:
        processed_include_headers = tuple((to_bytes(h.lower()) for h in sorted(include_headers)))
    cache = _fingerprint_cache.setdefault(request, {})
    cache_key = (processed_include_headers, keep_fragments)
    if cache_key not in cache:
        headers: Dict[str, List[str]] = {}
        if processed_include_headers:
            for header in processed_include_headers:
                if header in request.headers:
                    headers[header.hex()] = [header_value.hex() for header_value in request.headers.getlist(header)]
        fingerprint_data = {'method': to_unicode(request.method), 'url': canonicalize_url(request.url, keep_fragments=keep_fragments), 'body': (request.body or b'').hex(), 'headers': headers}
        fingerprint_json = json.dumps(fingerprint_data, sort_keys=True)
        cache[cache_key] = hashlib.sha1(fingerprint_json.encode()).digest()
    return cache[cache_key]

----------

@inlineCallbacks
def test_wait_if_request_is_downloading(self):

    def _check_downloading(response):
        fp = self.fingerprint(req1)
        self.assertTrue(fp in self.info.downloading)
        self.assertTrue(fp in self.info.waiting)
        self.assertTrue(fp not in self.info.downloaded)
        self.assertEqual(len(self.info.waiting[fp]), 2)
        return response
    rsp1 = Response('http://url')

    def rsp1_func():
        dfd = Deferred().addCallback(_check_downloading)
        reactor.callLater(0.1, dfd.callback, rsp1)
        return dfd

    def rsp2_func():
        self.fail('it must cache rsp1 result and must not try to redownload')
    req1 = Request('http://url', meta=dict(response=rsp1_func))
    req2 = Request(req1.url, meta=dict(response=rsp2_func))
    item = dict(requests=[req1, req2])
    new_item = (yield self.pipe.process_item(item, self.spider))
    self.assertEqual(new_item['results'], [(True, rsp1), (True, rsp1)])

----------



Test Class Name: MediaPipelineTestCase