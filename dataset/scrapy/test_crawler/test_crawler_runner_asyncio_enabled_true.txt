@defer.inlineCallbacks
def crawl(self, *args, **kwargs):
    if self.crawling:
        raise RuntimeError('Crawling already taking place')
    self.crawling = True
    try:
        self.spider = self._create_spider(*args, **kwargs)
        self.engine = self._create_engine()
        start_requests = iter(self.spider.start_requests())
        yield self.engine.open_spider(self.spider, start_requests)
        yield defer.maybeDeferred(self.engine.start)
    except Exception:
        self.crawling = False
        if self.engine is not None:
            yield self.engine.close()
        raise

----------

@defer.inlineCallbacks
def test_crawler_runner_asyncio_enabled_true(self):
    if self.reactor_pytest == 'asyncio':
        CrawlerRunner(settings={'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor', 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7'})
    else:
        msg = 'The installed reactor \\(.*?\\) does not match the requested one \\(.*?\\)'
        with self.assertRaisesRegex(Exception, msg):
            runner = CrawlerRunner(settings={'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor', 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7'})
            yield runner.crawl(NoRequestsSpider)

----------



Test Class Name: CrawlerRunnerHasSpider