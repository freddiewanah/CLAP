def extract_links(self, response):
    """Returns a list of :class:`~scrapy.link.Link` objects from the
        specified :class:`response <scrapy.http.Response>`.

        Only links that match the settings passed to the ``__init__`` method of
        the link extractor are returned.

        Duplicate links are omitted if the ``unique`` attribute is set to ``True``,
        otherwise they are returned.
        """
    base_url = get_base_url(response)
    if self.restrict_xpaths:
        docs = [subdoc for x in self.restrict_xpaths for subdoc in response.xpath(x)]
    else:
        docs = [response.selector]
    all_links = []
    for doc in docs:
        links = self._extract_links(doc, response.url, response.encoding, base_url)
        all_links.extend(self._process_links(links))
    if self.link_extractor.unique:
        return unique_list(all_links)
    return all_links

----------

def test_extract_filter_allowed_domains(self):
    lx = self.extractor_cls(allow_domains=('google.com',))
    self.assertEqual([link for link in lx.extract_links(self.response)], [Link(url='http://www.google.com/something', text='')])

----------



Test Class Name: LinkExtractorTestCase