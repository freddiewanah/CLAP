def process_response(self, request, response, spider):
    self.stats.inc_value('downloader/response_count', spider=spider)
    self.stats.inc_value(f'downloader/response_status_count/{response.status}', spider=spider)
    reslen = len(response.body) + get_header_size(response.headers) + get_status_size(response.status) + 4
    self.stats.inc_value('downloader/response_bytes', reslen, spider=spider)
    return response

----------

def test_response_len(self):
    body = (b'', b'not_empty')
    headers = ({}, {'lang': 'en'}, {'lang': 'en', 'User-Agent': 'scrapy'})
    test_responses = [Response(url='scrapytest.org', status=200, body=r[0], headers=r[1]) for r in product(body, headers)]
    for test_response in test_responses:
        self.crawler.stats.set_value('downloader/response_bytes', 0)
        self.mw.process_response(self.req, test_response, self.spider)
        with warnings.catch_warnings():
            warnings.simplefilter('ignore', ScrapyDeprecationWarning)
            resp_size = len(response_httprepr(test_response))
        self.assertStatsEqual('downloader/response_bytes', resp_size)

----------



Test Class Name: TestDownloaderStats