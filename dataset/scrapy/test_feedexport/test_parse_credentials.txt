@classmethod
def from_crawler(cls, crawler, uri, *, feed_options=None):
    return build_storage(cls, uri, access_key=crawler.settings['AWS_ACCESS_KEY_ID'], secret_key=crawler.settings['AWS_SECRET_ACCESS_KEY'], session_token=crawler.settings['AWS_SESSION_TOKEN'], acl=crawler.settings['FEED_STORAGE_S3_ACL'] or None, endpoint_url=crawler.settings['AWS_ENDPOINT_URL'] or None, feed_options=feed_options)

----------

def test_parse_credentials(self):
    skip_if_no_boto()
    aws_credentials = {'AWS_ACCESS_KEY_ID': 'settings_key', 'AWS_SECRET_ACCESS_KEY': 'settings_secret', 'AWS_SESSION_TOKEN': 'settings_token'}
    crawler = get_crawler(settings_dict=aws_credentials)
    storage = S3FeedStorage.from_crawler(crawler, 's3://mybucket/export.csv')
    self.assertEqual(storage.access_key, 'settings_key')
    self.assertEqual(storage.secret_key, 'settings_secret')
    self.assertEqual(storage.session_token, 'settings_token')
    storage = S3FeedStorage('s3://mybucket/export.csv', aws_credentials['AWS_ACCESS_KEY_ID'], aws_credentials['AWS_SECRET_ACCESS_KEY'], session_token=aws_credentials['AWS_SESSION_TOKEN'])
    self.assertEqual(storage.access_key, 'settings_key')
    self.assertEqual(storage.secret_key, 'settings_secret')
    self.assertEqual(storage.session_token, 'settings_token')
    storage = S3FeedStorage('s3://uri_key:uri_secret@mybucket/export.csv', aws_credentials['AWS_ACCESS_KEY_ID'], aws_credentials['AWS_SECRET_ACCESS_KEY'])
    self.assertEqual(storage.access_key, 'uri_key')
    self.assertEqual(storage.secret_key, 'uri_secret')

----------



Test Class Name: S3FeedStorageTest