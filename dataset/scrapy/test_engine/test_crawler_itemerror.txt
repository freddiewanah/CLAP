def run(self, args, opts):
    if len(args) < 1:
        raise UsageError()
    elif len(args) > 1:
        raise UsageError("running 'scrapy crawl' with more than one spider is not supported")
    spname = args[0]
    crawl_defer = self.crawler_process.crawl(spname, **opts.spargs)
    if getattr(crawl_defer, 'result', None) is not None and issubclass(crawl_defer.result.type, Exception):
        self.exitcode = 1
    else:
        self.crawler_process.start()
        if self.crawler_process.bootstrap_failed or (hasattr(self.crawler_process, 'has_exception') and self.crawler_process.has_exception):
            self.exitcode = 1

----------

@defer.inlineCallbacks
def test_crawler_itemerror(self):
    run = CrawlerRun(ItemZeroDivisionErrorSpider)
    yield run.run()
    self._assert_items_error(run)

----------

def _assert_items_error(self, run: CrawlerRun):
    self.assertEqual(2, len(run.itemerror))
    for (item, response, spider, failure) in run.itemerror:
        self.assertEqual(failure.value.__class__, ZeroDivisionError)
        self.assertEqual(spider, run.spider)
        self.assertEqual(item['url'], response.url)
        if 'item1.html' in item['url']:
            self.assertEqual('Item 1 name', item['name'])
            self.assertEqual('100', item['price'])
        if 'item2.html' in item['url']:
            self.assertEqual('Item 2 name', item['name'])
            self.assertEqual('200', item['price'])

Test Class Name: EngineTest