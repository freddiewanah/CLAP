@abstractmethod
def allowed(self, url, user_agent):
    """Return ``True`` if  ``user_agent`` is allowed to crawl ``url``, otherwise return ``False``.

        :param url: Absolute URL
        :type url: str

        :param user_agent: User agent
        :type user_agent: str
        """
    pass

----------

def test_allowed(self):
    robotstxt_robotstxt_body = 'User-agent: * \nDisallow: /disallowed \nAllow: /allowed \nCrawl-delay: 10'.encode('utf-8')
    rp = self.parser_cls.from_crawler(crawler=None, robotstxt_body=robotstxt_robotstxt_body)
    self.assertTrue(rp.allowed('https://www.site.local/allowed', '*'))
    self.assertFalse(rp.allowed('https://www.site.local/disallowed', '*'))

----------



Test Class Name: BaseRobotParserTest